{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99592f76-4963-42ee-a97e-fef14500e639",
   "metadata": {},
   "source": [
    "# Individual Assignment\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome! This notebook will be your individual assignment and guide you through a data exploration workflow.\n",
    "In the following cells you find the instructions for the individual steps. You can either replace these instructions with yours solutions or add your solutions in a new cell after the instructions.\n",
    "\n",
    "**Please make sure to keep the headlines as they are,** so we can recognize which solution belongs to which section for grading.\n",
    "\n",
    "### About Jupyter Notebooks\n",
    "\n",
    "Jupyter notebooks allow you to switch between Markdown text and Python code to create an interactive document.\n",
    "This makes them very well suited for exploratory tasks, tutorials and explanations. \n",
    "Please make sure that you are familiar with the basic operation of these notebooks and can use the cells appropriately.\n",
    "\n",
    "**You may always add additional cells if they help to better structure your text or code.**\n",
    "\n",
    "### Handing in the Task\n",
    "\n",
    "Please submit this notebook file (and only the notebook file) with your modifications.\n",
    "**Make sure you have listed all used frameworks and their version** (besides the Python standard library) **in Part 2** so we can run your code.\n",
    "\n",
    "### Grading\n",
    "\n",
    "Here you can see the grading criteria, wich we will use for establishing your final score.\n",
    "\n",
    "#### Overall\n",
    "\n",
    "> Each of these criteria gives between 0 and 2 points, with\n",
    "> 0 = rarely fulfilled\n",
    "> 1 = fulfilled to an acceptable level\n",
    "> 2 = expectation exceeded \n",
    "\n",
    "* Code quality\n",
    "    * PEP-8 compliant code\n",
    "    * Use of _speaking_ variable names\n",
    "    * Comments aid understanding without being excessive\n",
    "    * Use of functions to structure repeated tasks\n",
    "    * Use of classes to structure complex data and achieve separation of concerns\n",
    "    * Functions and classes have structured, consistent and informative docstrings\n",
    "    * Use of established frameworks to handle complex tasks\n",
    "    * Use of type hints\n",
    "* Written sections\n",
    "    * Clear communication of thought process\n",
    "    * Use of text formatting to structure writeup\n",
    "    * Sources and references are present and relevant to the context\n",
    "    * Factual correctness of written contents\n",
    "\n",
    "#### Individual parts\n",
    "\n",
    "Each individual part (Part 1 - Part 6) is rated with between 0 and 2 points as explained above.\n",
    "**Reaching 3 points in the individual parts is a requirement for passing the assignment.**\n",
    "\n",
    "#### Bonus Points\n",
    "\n",
    "* The data processing workflow also works with a different data set of the same kind (+2)\n",
    "    * Will be tested by changing the link to the data to point to a modified version of the original data set\n",
    "* Solved Task 7 (+2)\n",
    "\n",
    "#### Summary\n",
    "\n",
    "| Section               | Maximum Points |\n",
    "|-----------------------|----------------|\n",
    "| Overall               |             24 |\n",
    "| Individual Parts      |             12 |\n",
    "| Bonus                 |              4 |\n",
    "| Total points possible |             40 |\n",
    "| Raquirement for 1.0   |             36 |\n",
    "| Requirement for 2.0   |             24 |\n",
    "| Requirement for 3.0   |             18 |\n",
    "| Requirement for 4.0   |             12 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d51a4f-616d-451f-a59c-08fee9b69e66",
   "metadata": {},
   "source": [
    "## Part 1) Choice of Data Source\n",
    "\n",
    "### Choose a data set that you whish to analyze. \n",
    "The data must be available online for cross referencing (please add a link where to find it).\n",
    "Possible data sources include, but are not limited to, \n",
    "* [zenodo](https://zenodo.org/)\n",
    "* [rodare](https://rodare.hzdr.de/)\n",
    "* [destatis](https://www.destatis.de/EN/Home/_node.html)\n",
    "* The [NOAA](https://www.noaa.gov/nodd/datasets)\n",
    "* [tableau](https://www.tableau.com/learn/articles/free-public-data-sets)\n",
    "* [kaggle](https://www.kaggle.com/datasets)\n",
    "\n",
    "**Please make sure to check the size of the data set,** if it is too small, there is not much to analyze, if it is too large the download and evaluation will take too long.\n",
    "Data sets between 100KB and 1GB should be fine. \n",
    "\n",
    "If the file adheres to a standardized data format, name and link the standard document (if publicly available, otherwise refer to where to get the standard).\n",
    "Make sure to include the proper citation for the file you are using.\n",
    "\n",
    "### Characterize the data source you have chosen for your assignment.\n",
    "Explain the contents, format and structure of the data file.\n",
    "Highlight potential pitfalls or particular quirks in the data set that you may have to take care of during your implementation.",
    "\n",
    "\n",
    "## Used Datasets:\n",
    "Kaggle: Fast Food Restaurants Across America - A list of 10,000 restaurants and their locations.\n",
    "\n",
    "Kaggle: Dangerous Places in USA : 2013 - 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a47cd7-04b7-4b2a-9790-016776684906",
   "metadata": {},
   "source": [
    "## Part 2) Choice of Frameworks\n",
    "\n",
    "Investigate data processing and visualization frameworks and choose which ones to use in your project.\n",
    "Create a brief comparison of the frameworks you have researched, their benefits and drawbacks and how they can interact / support each other. \n",
    "Make sure they can either support the data format you have choosen or outline how you are going to load the data otherwise.\n",
    "\n",
    "Frameworks used: numpy, pandas, matplotlib, datetime, scipy, plotly, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268828fe-218e-4b0e-b592-f331739c7387",
   "metadata": {},
   "source": [
    "## Part 3) Loading the Data\n",
    "\n",
    "In the following cell write the code necessary to acquire the data from your online source.\n",
    "**Do not copy the data itself into this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "701ac93f-15b1-4cdb-ac16-3e1f0c553dc5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Put the data loading code here\n",
    "# After loading, print out a sample of the raw data as it was loaded\n",
    "\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"imtkaggleteam/fast-food-restaurants-across-america\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "16db9c65-a272-4d84-a3d2-a2995a99e8bf",
   "metadata": {},
   "source": [
    "## Part 4) Cleaning the data\n",
    "\n",
    "Your data set may have some quirks, strange formatting, incomplete entries or invalid data.\n",
    "Note down any particularities you find and your intended steps to correct them.\n",
    "Clean up the raw data you have loaded to bring it into a presentable shape, that can serve as the basis of future processing steps without having to worry about corner cases.\n",
    "You may create, split, combine, discard, re-format or re-label rows and columns as needed.\n",
    "Try to keep the cleaning procedure as generic as possible, so it could also work on a different data set of the same kind."
   ]
  },
  {
   "cell_type": "code",
   "id": "63a5b828-642c-42ed-aa59-290918223e96",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Add your data cleaning code here\n",
    "# After cleaning, print out the same sample as before, but this time in the cleaned state\n",
    "# Alle CSV-Dateien im Verzeichnis finden\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# Alle Dateien einlesen und in einer Liste speichern\n",
    "# 1. CSV-Dateien einlesen\n",
    "df1 = pd.read_csv(path + \"\\\\Datafiniti_Fast_Food_Restaurants.csv\")\n",
    "df2 = pd.read_csv(path + \"\\\\Datafiniti_Fast_Food_Restaurants_Jun19.csv\")\n",
    "\n",
    "# In ein gemeinsames DataFrame zusammenf√ºhren\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "combined_unique = combined_df.drop_duplicates()\n",
    "\n",
    "# Ausgabe der Spaltennamen (zur Kontrolle)\n",
    "print(\"Vor dem Entfernen:\", len(combined_df))\n",
    "print(\"Nach dem Entfernen:\", len(combined_unique))\n",
    "\n",
    "# 4. Optional: Ergebnis speichern\n",
    "combined_unique.to_csv(path + \"\\\\fast_food_vereint_ohne_duplikate.csv\", index=False)\n",
    "\n",
    "# Beispiel: Nur Restaurants in Kalifornien (province == \"CA\")\n",
    "california_restaurants = combined_df[combined_df[\"province\"] == \"CA\"]\n",
    "\n",
    "# Ausgabe von ein paar Beispielen\n",
    "print(california_restaurants.head())\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bfe21b2c-d68a-4732-824b-c692707b31f2",
   "metadata": {},
   "source": [
    "## Part 5) Fundamental Exploration\n",
    "\n",
    "Create a statistical analysis for each of the properties recorded in the data set.\n",
    "\n",
    "* For numerical data calculate the minimum and maximum values and where/when they appear, the mean value as well as the standard derivation.\n",
    "* For categorical data create a table how often each category appears\n",
    "* For time/date colums indicate the covered timespan and the average frequency of events\n",
    "* For any other kind of data discuss and implement a suitable statistical characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975ae7fd-4cba-4efa-9ebf-1023212c8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your statistical analysis here\n",
    "# Print the analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41706ed9-54cf-46f4-93d0-dead8444e205",
   "metadata": {},
   "source": [
    "## Part 6) Visualization\n",
    "\n",
    "Choose a _value over time_ or _two sequences of values_. \n",
    "Shortly discuss how they are related (or how the value behaves with relation to time) and which visualization forms are suitable to present this relationship.\n",
    "Create a plot to visualize this relationship between these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c79a870-f6ea-420f-b4bd-75e2201b934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your visualization here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeeaedf-3b8d-450c-8cd8-5af9518343f4",
   "metadata": {},
   "source": [
    "## Part 7) Bonus: Highlight\n",
    "\n",
    "Find a section in your data set with notable features (like strong derivations, extreme values, suspicious corelations, ‚Ä¶).\n",
    "Characterize those sections verbally and by statistical means and visualize the notable features.\n",
    "Use a different kinds of visualization to explain the observed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c3b03a-0488-488c-a0ac-3309efd2f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your highlight code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
